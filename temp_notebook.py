#!/usr/bin/env python
# coding: utf-8

# # ãƒˆãƒ¨ã‚¿æ ª (TM) â€” ç¿Œæ—¥çµ‚å€¤äºˆæ¸¬ + å£²è²·åˆ¤æ–­ï¼ˆBuy/Sellï¼‰
# 
# **ç›®çš„**: 2020/09ã€œ2025/06 ã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã€  
# 1) ç¿Œæ—¥ã®çµ‚å€¤ã‚’**å›å¸°**ã§äºˆæ¸¬ã—ã€  
# 2) ãã®äºˆæ¸¬ã«åŸºã¥ã„ã¦**å£²è²·åˆ¤æ–­ï¼ˆBuy/Sellï¼‰**ã®**åˆ†é¡**ã‚’è¡Œã†ã€‚
# 
# **ãƒã‚¤ãƒ³ãƒˆ**  
# - ãƒ­ãƒ¼ã‚«ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ« (`data/TM_1980-01-01_2025-06-27.csv`) ã‹ã‚‰ç›´æ¥ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
# - **æ¨™æº–LSTM** ã¨ **æ”¹è‰¯LSTM**ï¼ˆBiLSTM, AdamW, Huber Lossï¼‰ã®2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒ
# - ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆç·šå½¢å›å¸°ï¼‰ã¨æ¯”è¼ƒã€ã•ã‚‰ã«**æŒ‡æ¨™å¯è¦–åŒ–**ã€**å˜ç´”ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ**ã‚’å®Ÿè£…
# - åŒ…æ‹¬çš„ãªå¯è¦–åŒ–æ©Ÿèƒ½ã«ã‚ˆã‚Šã€ãƒ‡ãƒ¼ã‚¿ãƒ»å­¦ç¿’ãƒ»äºˆæ¸¬ãƒ»å–å¼•æˆ¦ç•¥ã‚’å¤šè§’çš„ã«åˆ†æ
# 
# ---
# 
# ## âš ï¸ é‡è¦ï¼šå®Ÿè¡Œé †åºã«ã¤ã„ã¦
# 
# **ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯å¿…ãšä¸Šã‹ã‚‰é †ç•ªã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚**
# 
# ### åŸºæœ¬çš„ãªå®Ÿè¡Œãƒ•ãƒ­ãƒ¼ï¼š
# 
# 1. **Imports** â†’ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿
# 2. **Parameters** â†’ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
# 3. **ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•°** â†’ CSVèª­ã¿è¾¼ã¿é–¢æ•°å®šç¾©
# 4. **ãƒ‡ãƒ¼ã‚¿å–å¾—** â†’ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨pickleä¿å­˜
# 5. **ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–** â†’ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
# 6. **ç‰¹å¾´é‡ç”Ÿæˆ** â†’ ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™è¨ˆç®—
# 7. **ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™å¯è¦–åŒ–** â†’ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
# 8. **ğŸ”´ æ™‚ç³»åˆ—åˆ†å‰²** â†’ **é‡è¦ï¼** ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ (`scaler_X`, `scaler_y`) ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
# 9. **ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å¯è¦–åŒ–** â†’ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
# 10. **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å­¦ç¿’** â†’ ã‚»ãƒ«8ã®å®Ÿè¡ŒãŒå¿…é ˆ
# 11. **æ¨™æº–LSTMå­¦ç¿’** â†’ ã‚»ãƒ«8ã®å®Ÿè¡ŒãŒå¿…é ˆ
# 12. **ğŸ†• æ”¹è‰¯LSTMå­¦ç¿’** â†’ ã‚»ãƒ«8, 11ã®å®Ÿè¡ŒãŒå¿…é ˆ
# 13. **äºˆæ¸¬çµæœå¯è¦–åŒ–** â†’ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
# 14. **ğŸ”´ åˆ†é¡ï¼ˆBuy/Sellåˆ¤å®šï¼‰** â†’ **é‡è¦ï¼** `close_test_tail`ãªã©ã‚’å®šç¾©
# 15. **ğŸ†• æ”¹è‰¯LSTMã®åˆ†é¡ãƒ»ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ** â†’ ã‚»ãƒ«14ã®å®Ÿè¡ŒãŒå¿…é ˆ
# 16. **åˆ†é¡æ€§èƒ½å¯è¦–åŒ–** â†’ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
# 17. **ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ** â†’ ã‚»ãƒ«14ã®å®Ÿè¡ŒãŒå¿…é ˆ
# 18. **ä¿å­˜** â†’ ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®ä¿å­˜
# 19. **ç·åˆã‚µãƒãƒªãƒ¼** â†’ å…¨ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ
# 
# ### âš ï¸ ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸã‚‰
# 
# - `NameError: name 'xxx' is not defined` â†’ ä¸Šã®ã‚»ãƒ«ã‚’é£›ã°ã—ã¦ã„ã¾ã™
# - ç‰¹ã«**ã‚»ãƒ«8ï¼ˆæ™‚ç³»åˆ—åˆ†å‰²ï¼‰**ã¨**ã‚»ãƒ«14ï¼ˆåˆ†é¡ï¼‰**ã¯å¿…é ˆ
# - `Kernel â†’ Restart & Run All` ã§å…¨ã‚»ãƒ«å†å®Ÿè¡Œã‚’æ¨å¥¨
# 
# ã‚»ãƒ«ã‚’é£›ã°ã—ã¦å®Ÿè¡Œã™ã‚‹ã¨ `NameError` ãŒç™ºç”Ÿã—ã¾ã™ã€‚

# In[1]:


# === Imports ===
import os
import sys
import math
import gc
import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
import joblib
from pathlib import Path
from datetime import datetime

# Plot
import matplotlib.pyplot as plt

# ML/DL
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from sklearn.model_selection import TimeSeriesSplit

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

print('TensorFlow:', tf.__version__)
print('All imports successful!')


# In[2]:


# === Parameters ===
TICKER = "TM"      # ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Š (NYSE: TM)
START_DATE = "1980-03-17"
END_DATE   = "2025-06-27"  # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æœ€çµ‚æ—¥ã«åˆã‚ã›ã‚‹

# å­¦ç¿’ãƒã‚¤ãƒ‘ãƒ©
WINDOW_SIZE = 20     # ä½•æ—¥åˆ†ã®å±¥æ­´ã§ç¿Œæ—¥ã‚’äºˆæ¸¬ã™ã‚‹ã‹
BATCH_SIZE  = 32
EPOCHS      = 30
VAL_SPLIT   = 0.0     # æ˜ç¤ºçš„ã«æ™‚ç³»åˆ—åˆ†å‰²ã™ã‚‹ã®ã§ 0

# æ™‚ç³»åˆ—åˆ†å‰²ï¼ˆå›ºå®šå¢ƒç•Œï¼‰
SPLIT_TRAIN_END = "2024-03-31"
SPLIT_VAL_END   = "2025-03-31"  # val: 2024-04-01ã€œ2025-03-31
# test: 2025-04-01ã€œ2025-06-27

# ä¹±æ•°ã‚·ãƒ¼ãƒ‰
SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)


# In[3]:


# === ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•° ===
def load_csv_data(csv_path):
    """
    ãƒ­ãƒ¼ã‚«ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
    """
    df = pd.read_csv(csv_path)

    # CSV ã®2è¡Œç›®ãŒãƒ†ã‚£ãƒƒã‚«ãƒ¼åã®ã¿ã®å ´åˆã¯å‰Šé™¤
    if len(df) > 0 and df.iloc[0].isna().all():
        df = df.iloc[1:].reset_index(drop=True)

    # dateåˆ—ã‚’æ¢ã™
    candidate_date_cols = [c for c in df.columns if str(c).strip().lower() in {'date', 'datetime'}]
    if candidate_date_cols:
        date_col = candidate_date_cols[0]
        # æ—¥ä»˜ã¨ã—ã¦å¤‰æ›ã§ããªã„è¡Œã‚’å‰Šé™¤
        df = df[pd.to_datetime(df[date_col], errors='coerce').notna()]
        df[date_col] = pd.to_datetime(df[date_col])
        df = df.set_index(date_col)
    else:
        # å…ˆé ­åˆ—ãŒæ—¥ä»˜ã¨æƒ³å®š
        first_col = df.columns[0]
        df = df[pd.to_datetime(df[first_col], errors='coerce').notna()]
        df[first_col] = pd.to_datetime(df[first_col])
        df = df.set_index(first_col)

    # æ•°å€¤åˆ—ã¨ã—ã¦æ‰±ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹
    for col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    df = df.dropna(how='all')

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«æ¬ æãŒã‚ã‚‹è¡Œã‚’å‰Šé™¤
    df = df[df.index.notna()]
    df = df.sort_index()

    # åˆ—åã‚’å°æ–‡å­—ã«æƒãˆã‚‹
    cols = {c: str(c).lower().replace(' ', '').replace('_', '') for c in df.columns}
    df = df.rename(columns=cols)

    # å¿…é ˆåˆ—ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    must = ['open', 'high', 'low', 'close', 'adjclose', 'volume']
    for m in must:
        if m not in df.columns:
            # adjclose ãŒãªã„ã‚±ãƒ¼ã‚¹ã‚‚ã‚ã‚‹ã®ã§ Close ã‚’è¤‡è£½
            if m == 'adjclose' and 'close' in df.columns:
                df['adjclose'] = df['close']
            else:
                raise ValueError(f"Missing column: {m}")

    return df[['open','high','low','close','adjclose','volume']]

print('Data loading function defined.')


# In[4]:


# === ãƒ‡ãƒ¼ã‚¿å–å¾— ===
CSV_PATH = "data/TM_1980-01-01_2025-06-27.csv"

df = load_csv_data(CSV_PATH)

print('Data loaded successfully!')
print(f'Shape: {df.shape}')
print(f'Date range: {df.index.min()} to {df.index.max()}')
print('\nFirst few rows:')
print(df.head())
print('\nLast few rows:')
print(df.tail())
print('\nData statistics:')
print(df.describe())

# ä¿å­˜ï¼ˆãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«äº’æ›ï¼‰
df.to_pickle('df_ohlcv_7203T.pkl')
print('\nData saved to df_ohlcv_7203T.pkl')


# In[5]:


# === æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆå¿µã®ãŸã‚ï¼‰ ===
# dfãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
if 'df' not in dir():
    fallback_path = Path('df_ohlcv_7203T.pkl')
    if fallback_path.exists():
        df = pd.read_pickle(fallback_path)
        print(f"Loaded cached OHLCV data from {fallback_path}")
    else:
        raise RuntimeError('ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿(df)ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚å…ˆã«ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã‹ df_ohlcv_7203T.pkl ã‚’ç”¨æ„ã—ã¦ãã ã•ã„ã€‚')

df = df[(df.index >= pd.to_datetime(START_DATE)) & (df.index <= pd.to_datetime(END_DATE))].copy()
print(f'Filtered data shape: {df.shape}')

# === ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ãƒ»æ´¾ç”Ÿç‰¹å¾´é‡ ===
def rsi(series, period=14):
    delta = series.diff()
    up = delta.clip(lower=0)
    down = -1 * delta.clip(upper=0)
    ma_up = up.rolling(window=period, min_periods=period).mean()
    ma_down = down.rolling(window=period, min_periods=period).mean()
    rs = ma_up / (ma_down + 1e-9)
    return 100 - (100 / (1 + rs))

def macd(series, fast=12, slow=26, signal=9):
    ema_fast = series.ewm(span=fast, adjust=False).mean()
    ema_slow = series.ewm(span=slow, adjust=False).mean()
    macd_line = ema_fast - ema_slow
    signal_line = macd_line.ewm(span=signal, adjust=False).mean()
    hist = macd_line - signal_line
    return macd_line, signal_line, hist

def bollinger(series, window=20, num_std=2):
    ma = series.rolling(window=window, min_periods=window).mean()
    std = series.rolling(window=window, min_periods=window).std()
    upper = ma + num_std * std
    lower = ma - num_std * std
    width = (upper - lower) / (ma + 1e-9)
    return ma, upper, lower, width

# ä¸»è¦ãªçµ‚å€¤ãƒ™ãƒ¼ã‚¹ã§ç®—å‡º
close = df['close']

df['ret_1d'] = close.pct_change()
df['ma_7']   = close.rolling(7).mean()
df['ma_30']  = close.rolling(30).mean()
df['ema_7']  = close.ewm(span=7, adjust=False).mean()
df['ema_30'] = close.ewm(span=30, adjust=False).mean()
df['rsi_14'] = rsi(close, 14)

macd_line, signal_line, macd_hist = macd(close)
df['macd']   = macd_line
df['macd_s'] = signal_line
df['macd_h'] = macd_hist

bb_ma, bb_up, bb_lo, bb_w = bollinger(close, 20, 2)
df['bb_ma'] = bb_ma
df['bb_up'] = bb_up
df['bb_lo'] = bb_lo
df['bb_w']  = bb_w

# å‡ºæ¥é«˜ç³»
df['vol_chg'] = df['volume'].pct_change()

# 1æ—¥å…ˆã®çµ‚å€¤ï¼ˆå›å¸°ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰
df['target_close_t1'] = df['close'].shift(-1)

# 1æ—¥å…ˆãŒä¸Šæ˜‡ãªã‚‰1ï¼ˆBuyï¼‰ã€ä¸‹é™ãªã‚‰0ï¼ˆSellï¼‰
df['target_buy'] = (df['target_close_t1'] > df['close']).astype(float)

# æ¬ æé™¤å»
df = df.dropna().copy()
print('Final shape with features:', df.shape)
print('\nFirst few rows with features:')
print(df.head(3))
display(df)


# In[6]:


# === ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã®è©³ç´°å¯è¦–åŒ– ===
fig = plt.figure(figsize=(16, 12))
gs = fig.add_gridspec(4, 2, hspace=0.3, wspace=0.3)

# 1. çµ‚å€¤ + ç§»å‹•å¹³å‡ç·š
ax1 = fig.add_subplot(gs[0, :])
ax1.plot(df.index, df['close'], label='Close', linewidth=1.5, color='black', alpha=0.7)
ax1.plot(df.index, df['ma_7'], label='MA(7)', linewidth=1, linestyle='--', color='blue')
ax1.plot(df.index, df['ma_30'], label='MA(30)', linewidth=1, linestyle='--', color='red')
ax1.plot(df.index, df['ema_7'], label='EMA(7)', linewidth=1, linestyle=':', color='cyan')
ax1.plot(df.index, df['ema_30'], label='EMA(30)', linewidth=1, linestyle=':', color='magenta')
ax1.set_title('Toyota (TM) Close Price with Moving Averages', fontsize=14, fontweight='bold')
ax1.set_xlabel('Date')
ax1.set_ylabel('Price ($)')
ax1.legend(loc='best')
ax1.grid(True, alpha=0.3)

# 2. ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
ax2 = fig.add_subplot(gs[1, :])
ax2.plot(df.index, df['close'], label='Close', linewidth=1.5, color='black')
ax2.plot(df.index, df['bb_ma'], label='BB MA(20)', linewidth=1, linestyle='--', color='blue')
ax2.fill_between(df.index, df['bb_up'], df['bb_lo'], alpha=0.2, color='gray', label='BB Bands')
ax2.plot(df.index, df['bb_up'], linewidth=0.8, linestyle=':', color='green', label='Upper Band')
ax2.plot(df.index, df['bb_lo'], linewidth=0.8, linestyle=':', color='red', label='Lower Band')
ax2.set_title('Bollinger Bands', fontsize=14, fontweight='bold')
ax2.set_xlabel('Date')
ax2.set_ylabel('Price ($)')
ax2.legend(loc='best')
ax2.grid(True, alpha=0.3)

# 3. RSI
ax3 = fig.add_subplot(gs[2, 0])
ax3.plot(df.index, df['rsi_14'], linewidth=1, color='purple')
ax3.axhline(70, linestyle='--', color='red', linewidth=1, label='Overbought (70)')
ax3.axhline(30, linestyle='--', color='green', linewidth=1, label='Oversold (30)')
ax3.axhline(50, linestyle='-', color='gray', linewidth=0.5, alpha=0.5)
ax3.fill_between(df.index, 30, 70, alpha=0.1, color='yellow')
ax3.set_title('RSI (14)', fontsize=12, fontweight='bold')
ax3.set_xlabel('Date')
ax3.set_ylabel('RSI')
ax3.legend(loc='best')
ax3.grid(True, alpha=0.3)
ax3.set_ylim(0, 100)

# 4. MACD
ax4 = fig.add_subplot(gs[2, 1])
ax4.plot(df.index, df['macd'], label='MACD Line', linewidth=1, color='blue')
ax4.plot(df.index, df['macd_s'], label='Signal Line', linewidth=1, color='red')
ax4.bar(df.index, df['macd_h'], label='Histogram', alpha=0.3, color='gray', width=1)
ax4.axhline(0, linestyle='-', color='black', linewidth=0.5)
ax4.set_title('MACD', fontsize=12, fontweight='bold')
ax4.set_xlabel('Date')
ax4.set_ylabel('MACD Value')
ax4.legend(loc='best')
ax4.grid(True, alpha=0.3)

# 5. æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³
ax5 = fig.add_subplot(gs[3, 0])
colors = ['green' if x > 0 else 'red' for x in df['ret_1d']]
ax5.bar(df.index, df['ret_1d'], color=colors, alpha=0.6, width=1)
ax5.axhline(0, linestyle='-', color='black', linewidth=0.5)
ax5.set_title('Daily Returns', fontsize=12, fontweight='bold')
ax5.set_xlabel('Date')
ax5.set_ylabel('Return')
ax5.grid(True, alpha=0.3)

# 6. å‡ºæ¥é«˜å¤‰åŒ–ç‡
ax6 = fig.add_subplot(gs[3, 1])
ax6.plot(df.index, df['vol_chg'], linewidth=0.8, color='coral')
ax6.axhline(0, linestyle='-', color='black', linewidth=0.5)
ax6.set_title('Volume Change Rate', fontsize=12, fontweight='bold')
ax6.set_xlabel('Date')
ax6.set_ylabel('Volume Change')
ax6.grid(True, alpha=0.3)

plt.suptitle('Technical Indicators Overview', fontsize=16, fontweight='bold', y=0.995)
plt.show()

print("Technical indicators visualization complete!")


# In[7]:


# === æ™‚ç³»åˆ—åˆ†å‰² ===
# æ³¨æ„: ã“ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ä»¥ä¸‹ã®é‡è¦ãªå¤‰æ•°ãŒä½œæˆã•ã‚Œã¾ã™ï¼š
# - scaler_X, scaler_y (ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼)
# - y_train_reg_scaled, y_val_reg_scaled, y_test_reg_scaled (ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ¸ˆã¿ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ)
# - y_train_reg, y_val_reg, y_test_reg (å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ)
# ã“ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã›ãšã«å¾Œç¶šã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚Šã¾ã™ã€‚

train = df[df.index <= SPLIT_TRAIN_END].copy()
val   = df[(df.index > SPLIT_TRAIN_END) & (df.index <= SPLIT_VAL_END)].copy()
test  = df[df.index > SPLIT_VAL_END].copy()

print('train:', train.index.min(), '->', train.index.max(), len(train))
print('val  :', val.index.min(),   '->', val.index.max(),   len(val))
print('test :', test.index.min(),  '->', test.index.max(),  len(test))

# ç‰¹å¾´é‡ã‚«ãƒ©ãƒ 
FEATURE_COLS = [
    'open','high','low','close','adjclose','volume',
    'ret_1d','ma_7','ma_30','ema_7','ema_30','rsi_14',
    'macd','macd_s','macd_h','bb_ma','bb_up','bb_lo','bb_w','vol_chg'
]

def make_window_dataset(df_part, feature_cols, target_col, window):
    X_list, y_list = [], []
    feats = df_part[feature_cols].values
    target = df_part[target_col].values
    for i in range(len(df_part) - window):
        X_list.append(feats[i:i+window])
        y_list.append(target[i+window])
    return np.array(X_list), np.array(y_list)

# ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã¯è¨“ç·´ã§fitã—ã€ä»–ã§transform
print('\nCreating scalers...')
scaler_X = StandardScaler()
scaler_X.fit(train[FEATURE_COLS].values)

# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆçµ‚å€¤ï¼‰ç”¨ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚‚åˆ¥é€”ä½œæˆ
scaler_y = StandardScaler()
scaler_y.fit(train[['target_close_t1']].values)
print('âœ“ Scalers created: scaler_X and scaler_y')

def scale_df(df_part):
    cp = df_part.copy()
    cp[FEATURE_COLS] = scaler_X.transform(cp[FEATURE_COLS].values)
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    cp['target_close_t1_scaled'] = scaler_y.transform(cp[['target_close_t1']].values)
    return cp

train_s = scale_df(train)
val_s   = scale_df(val)
test_s  = scale_df(test)

# å›å¸°ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆç¿Œæ—¥çµ‚å€¤ï¼‰ - ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ¸ˆã¿ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’ä½¿ç”¨
print('\nCreating window datasets...')
X_train_reg, y_train_reg_scaled = make_window_dataset(train_s, FEATURE_COLS, 'target_close_t1_scaled', WINDOW_SIZE)
X_val_reg,   y_val_reg_scaled   = make_window_dataset(val_s,   FEATURE_COLS, 'target_close_t1_scaled', WINDOW_SIZE)
X_test_reg,  y_test_reg_scaled  = make_window_dataset(test_s,  FEATURE_COLS, 'target_close_t1_scaled', WINDOW_SIZE)

# å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆè©•ä¾¡ç”¨ï¼‰
_, y_train_reg = make_window_dataset(train, FEATURE_COLS, 'target_close_t1', WINDOW_SIZE)
_, y_val_reg   = make_window_dataset(val,   FEATURE_COLS, 'target_close_t1', WINDOW_SIZE)
_, y_test_reg  = make_window_dataset(test,  FEATURE_COLS, 'target_close_t1', WINDOW_SIZE)

# åˆ†é¡ç”¨ï¼ˆBuy/Sellï¼‰
X_train_cls, y_train_cls = make_window_dataset(train_s, FEATURE_COLS, 'target_buy', WINDOW_SIZE)
X_val_cls,   y_val_cls   = make_window_dataset(val_s,   FEATURE_COLS, 'target_buy', WINDOW_SIZE)
X_test_cls,  y_test_cls  = make_window_dataset(test_s,  FEATURE_COLS, 'target_buy', WINDOW_SIZE)

print(f'\nâœ“ Dataset creation complete!')
print(f'  X_train_reg: {X_train_reg.shape}, y_train_reg: {y_train_reg.shape}')
print(f'  X_val_reg: {X_val_reg.shape}, y_val_reg: {y_val_reg.shape}')
print(f'  X_test_reg: {X_test_reg.shape}, y_test_reg: {y_test_reg.shape}')
print(f'\nScaled target statistics:')
print(f'  y_train_reg_scaled: mean={y_train_reg_scaled.mean():.4f}, std={y_train_reg_scaled.std():.4f}')
print(f'  y_test_reg_scaled: mean={y_test_reg_scaled.mean():.4f}, std={y_test_reg_scaled.std():.4f}')


# In[ ]:


# === ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã®å¯è¦–åŒ– ===
fig, axes = plt.subplots(2, 1, figsize=(15, 8))

# 1. å…¨æœŸé–“ã®çµ‚å€¤ã¨ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
ax1 = axes[0]
ax1.plot(df.index, df['close'], linewidth=1, color='gray', alpha=0.5, label='All Data')
ax1.plot(train.index, train['close'], linewidth=1.5, color='blue', label=f'Train ({len(train)} days)')
ax1.plot(val.index, val['close'], linewidth=1.5, color='orange', label=f'Val ({len(val)} days)')
ax1.plot(test.index, test['close'], linewidth=1.5, color='green', label=f'Test ({len(test)} days)')

# åˆ†å‰²å¢ƒç•Œç·š
ax1.axvline(pd.to_datetime(SPLIT_TRAIN_END), color='red', linestyle='--', linewidth=2, alpha=0.7, label='Train/Val Split')
ax1.axvline(pd.to_datetime(SPLIT_VAL_END), color='purple', linestyle='--', linewidth=2, alpha=0.7, label='Val/Test Split')

ax1.set_title('Data Split Visualization (Train/Val/Test)', fontsize=14, fontweight='bold')
ax1.set_xlabel('Date')
ax1.set_ylabel('Close Price ($)')
ax1.legend(loc='best')
ax1.grid(True, alpha=0.3)

# 2. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ï¼ˆBuy/Sellãƒ©ãƒ™ãƒ«ï¼‰ã®åˆ†å¸ƒ
ax2 = axes[1]
train_buy_ratio = train['target_buy'].mean()
val_buy_ratio = val['target_buy'].mean()
test_buy_ratio = test['target_buy'].mean()

splits = ['Train', 'Val', 'Test']
buy_ratios = [train_buy_ratio, val_buy_ratio, test_buy_ratio]
sell_ratios = [1-train_buy_ratio, 1-val_buy_ratio, 1-test_buy_ratio]

x = np.arange(len(splits))
width = 0.35

bars1 = ax2.bar(x - width/2, buy_ratios, width, label='Buy (1)', color='green', alpha=0.7)
bars2 = ax2.bar(x + width/2, sell_ratios, width, label='Sell (0)', color='red', alpha=0.7)

# ãƒãƒ¼ã®ä¸Šã«å‰²åˆã‚’è¡¨ç¤º
for bars in [bars1, bars2]:
    for bar in bars:
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.1%}', ha='center', va='bottom', fontsize=10)

ax2.set_ylabel('Ratio')
ax2.set_title('Target Variable Distribution (Buy/Sell) by Split', fontsize=14, fontweight='bold')
ax2.set_xticks(x)
ax2.set_xticklabels(splits)
ax2.legend()
ax2.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()

print(f"\nDataset Split Summary:")
print(f"  Train: {len(train):4d} days ({len(train)/len(df)*100:5.1f}%) - Buy: {train_buy_ratio:.1%}, Sell: {1-train_buy_ratio:.1%}")
print(f"  Val:   {len(val):4d} days ({len(val)/len(df)*100:5.1f}%) - Buy: {val_buy_ratio:.1%}, Sell: {1-val_buy_ratio:.1%}")
print(f"  Test:  {len(test):4d} days ({len(test)/len(df)*100:5.1f}%) - Buy: {test_buy_ratio:.1%}, Sell: {1-test_buy_ratio:.1%}")
print(f"\nWindow Dataset Shapes:")
print(f"  X_train_reg: {X_train_reg.shape}, X_val_reg: {X_val_reg.shape}, X_test_reg: {X_test_reg.shape}")


# In[ ]:


# === ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼šç·šå½¢å›å¸°ï¼ˆå›å¸°ï¼‰ ===
# ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’å¹³å‡ã§æ½°ã—ã¦å˜ç´”ç‰¹å¾´ã«è½ã¨ã™ç°¡æ˜“ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
def collapse_window_mean(X):
    # (N, window, F) -> (N, F) by mean
    return X.mean(axis=1)

Xtr_bl = collapse_window_mean(X_train_reg)
Xv_bl  = collapse_window_mean(X_val_reg)
Xte_bl = collapse_window_mean(X_test_reg)

linr = LinearRegression()
linr.fit(Xtr_bl, y_train_reg_scaled)

# äºˆæ¸¬ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ¸ˆã¿ï¼‰
pred_tr_bl_scaled = linr.predict(Xtr_bl)
pred_v_bl_scaled  = linr.predict(Xv_bl)
pred_te_bl_scaled = linr.predict(Xte_bl)

# é€†ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™
pred_tr_bl = scaler_y.inverse_transform(pred_tr_bl_scaled.reshape(-1, 1)).ravel()
pred_v_bl  = scaler_y.inverse_transform(pred_v_bl_scaled.reshape(-1, 1)).ravel()
pred_te_bl = scaler_y.inverse_transform(pred_te_bl_scaled.reshape(-1, 1)).ravel()

def rmse(y, p): return math.sqrt(mean_squared_error(y, p))

print('Baseline Linear Regression')
print('  Train RMSE:', rmse(y_train_reg, pred_tr_bl))
print('  Val   RMSE:', rmse(y_val_reg,   pred_v_bl))
print('  Test  RMSE:', rmse(y_test_reg,  pred_te_bl))

print('  Test R2  :', r2_score(y_test_reg, pred_te_bl))


# In[ ]:


# === LSTMï¼ˆå›å¸°ï¼šç¿Œæ—¥çµ‚å€¤ï¼‰ ===
tf.keras.backend.clear_session()

model_reg = Sequential([
    LSTM(64, return_sequences=True, input_shape=(X_train_reg.shape[1], X_train_reg.shape[2])),
    Dropout(0.2),
    LSTM(64),
    Dense(1, activation='linear')
])
model_reg.compile(optimizer='adam', loss='mse')

print("Model Architecture:")
model_reg.summary()

callbacks = [
    EarlyStopping(patience=10, restore_best_weights=True, monitor='val_loss'),
    ReduceLROnPlateau(patience=5, factor=0.5, monitor='val_loss', verbose=1),
    ModelCheckpoint('best_regression.keras', monitor='val_loss', save_best_only=True, verbose=0)
]

hist = model_reg.fit(
    X_train_reg, y_train_reg_scaled,
    validation_data=(X_val_reg, y_val_reg_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    callbacks=callbacks,
    verbose=1
)

# æ¨è«–ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ¸ˆã¿ï¼‰
pred_tr_scaled = model_reg.predict(X_train_reg, verbose=0).ravel()
pred_v_scaled  = model_reg.predict(X_val_reg, verbose=0).ravel()
pred_te_scaled = model_reg.predict(X_test_reg, verbose=0).ravel()

# é€†ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™
pred_tr = scaler_y.inverse_transform(pred_tr_scaled.reshape(-1, 1)).ravel()
pred_v  = scaler_y.inverse_transform(pred_v_scaled.reshape(-1, 1)).ravel()
pred_te = scaler_y.inverse_transform(pred_te_scaled.reshape(-1, 1)).ravel()

print('\n' + '='*60)
print('LSTM Regression Results')
print('='*60)
print(f'  Train RMSE: {rmse(y_train_reg, pred_tr):.4f}')
print(f'  Val   RMSE: {rmse(y_val_reg, pred_v):.4f}')
print(f'  Test  RMSE: {rmse(y_test_reg, pred_te):.4f}')
print(f'  Test R2:    {r2_score(y_test_reg, pred_te):.4f}')
print('='*60)

# === å­¦ç¿’æ›²ç·šã®è©³ç´°å¯è¦–åŒ– ===
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# 1. Lossæ›²ç·šï¼ˆé€šå¸¸ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
ax1 = axes[0, 0]
ax1.plot(hist.history['loss'], label='Train Loss', linewidth=2, color='blue')
ax1.plot(hist.history['val_loss'], label='Val Loss', linewidth=2, color='orange')
ax1.set_title('Training and Validation Loss', fontsize=12, fontweight='bold')
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Loss (MSE)')
ax1.legend()
ax1.grid(True, alpha=0.3)

# æœ€å°å€¤ã«ãƒãƒ¼ã‚«ãƒ¼
min_val_loss_epoch = np.argmin(hist.history['val_loss'])
min_val_loss = hist.history['val_loss'][min_val_loss_epoch]
ax1.plot(min_val_loss_epoch, min_val_loss, 'r*', markersize=15, 
         label=f'Best Val Loss: {min_val_loss:.4f} @ epoch {min_val_loss_epoch+1}')
ax1.legend()

# 2. Lossæ›²ç·šï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
ax2 = axes[0, 1]
ax2.plot(hist.history['loss'], label='Train Loss', linewidth=2, color='blue')
ax2.plot(hist.history['val_loss'], label='Val Loss', linewidth=2, color='orange')
ax2.set_title('Training and Validation Loss (Log Scale)', fontsize=12, fontweight='bold')
ax2.set_xlabel('Epoch')
ax2.set_ylabel('Loss (MSE)')
ax2.set_yscale('log')
ax2.legend()
ax2.grid(True, alpha=0.3)

# 3. Train/Valã®å·®åˆ†
ax3 = axes[1, 0]
loss_diff = np.array(hist.history['val_loss']) - np.array(hist.history['loss'])
ax3.plot(loss_diff, linewidth=2, color='red')
ax3.axhline(0, linestyle='--', color='black', linewidth=1)
ax3.set_title('Validation - Training Loss Gap', fontsize=12, fontweight='bold')
ax3.set_xlabel('Epoch')
ax3.set_ylabel('Loss Difference')
ax3.grid(True, alpha=0.3)

# 4. ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®æ”¹å–„ç‡
ax4 = axes[1, 1]
val_loss_improvement = np.diff(hist.history['val_loss'])
ax4.plot(range(1, len(val_loss_improvement)+1), val_loss_improvement, 
         marker='o', linewidth=1, markersize=4, color='purple')
ax4.axhline(0, linestyle='--', color='black', linewidth=1)
ax4.set_title('Validation Loss Improvement per Epoch', fontsize=12, fontweight='bold')
ax4.set_xlabel('Epoch')
ax4.set_ylabel('Loss Change')
ax4.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("\nTraining visualization complete!")


# In[ ]:


# === æ”¹è‰¯ç‰ˆ LSTMï¼ˆå›å¸°ï¼šç¿Œæ—¥çµ‚å€¤ï¼‰ ===
print('='*70)
print('Training Improved LSTM Model')
print('='*70)

tf.keras.backend.clear_session()

from tensorflow.keras.layers import Bidirectional, LayerNormalization
from tensorflow.keras.optimizers.schedules import CosineDecayRestarts
from tensorflow.keras.losses import Huber

# 1) å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« + AdamW + ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
initial_lr = 1e-3
lr_schedule = CosineDecayRestarts(
    initial_learning_rate=initial_lr,
    first_decay_steps=200,   # ãƒ‡ãƒ¼ã‚¿é‡/ãƒãƒƒãƒã«å¿œã˜ã¦èª¿æ•´å¯
    t_mul=2.0,
    m_mul=0.8,
    alpha=1e-4               # æœ€å°å­¦ç¿’ç‡
)
optimizer = tf.keras.optimizers.AdamW(
    learning_rate=lr_schedule,
    weight_decay=1e-4,
    clipnorm=1.0             # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
)

# 2) ãƒ¢ãƒ‡ãƒ«ï¼ˆBiLSTM + æ­£å‰‡åŒ–ï¼‰
model_reg_improved = Sequential([
    Bidirectional(LSTM(128, return_sequences=True),
                  input_shape=(X_train_reg.shape[1], X_train_reg.shape[2])),
    Dropout(0.30),
    LayerNormalization(),

    LSTM(64, return_sequences=False),
    Dropout(0.25),

    Dense(32, activation='swish'),
    Dropout(0.10),

    Dense(1, activation='linear')
])

# 3) Huberæå¤±ï¼ˆå¤–ã‚Œå€¤ã«å¼·ã„ï¼‰
model_reg_improved.compile(optimizer=optimizer, loss=Huber(delta=1.0))

print("Improved Model Architecture:")
model_reg_improved.summary()

callbacks_improved = [
    EarlyStopping(
        patience=15,
        restore_best_weights=True,
        monitor='val_loss',
        mode='min'
    ),
    ModelCheckpoint(
        'best_regression_improved.keras',
        monitor='val_loss',
        save_best_only=True,
        mode='min',
        verbose=0
    )
]

hist_improved = model_reg_improved.fit(
    X_train_reg, y_train_reg_scaled,
    validation_data=(X_val_reg, y_val_reg_scaled),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    callbacks=callbacks_improved,
    verbose=1,
    shuffle=False  # æ™‚ç³»åˆ—ã¯FalseãŒåŸºæœ¬
)

# æ¨è«–ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ¸ˆã¿ï¼‰
pred_tr_improved_scaled = model_reg_improved.predict(X_train_reg, verbose=0).ravel()
pred_v_improved_scaled  = model_reg_improved.predict(X_val_reg, verbose=0).ravel()
pred_te_improved_scaled = model_reg_improved.predict(X_test_reg, verbose=0).ravel()

# é€†ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™
pred_tr_improved = scaler_y.inverse_transform(pred_tr_improved_scaled.reshape(-1, 1)).ravel()
pred_v_improved  = scaler_y.inverse_transform(pred_v_improved_scaled.reshape(-1, 1)).ravel()
pred_te_improved = scaler_y.inverse_transform(pred_te_improved_scaled.reshape(-1, 1)).ravel()

print('\n' + '='*60)
print('Improved LSTM Regression Results')
print('='*60)
print(f'  Train RMSE: {rmse(y_train_reg, pred_tr_improved):.4f}')
print(f'  Val   RMSE: {rmse(y_val_reg, pred_v_improved):.4f}')
print(f'  Test  RMSE: {rmse(y_test_reg, pred_te_improved):.4f}')
print(f'  Test R2:    {r2_score(y_test_reg, pred_te_improved):.4f}')
print('='*60)

# === æ¯”è¼ƒï¼šãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ vs æ¨™æº–LSTM vs æ”¹è‰¯LSTM ===
print('\n' + '='*60)
print('Model Comparison Summary')
print('='*60)
print(f'{"Model":<25} {"Test RMSE":<12} {"Test RÂ²":<12}')
print('-'*60)
print(f'{"Baseline (Linear Reg)":<25} {rmse(y_test_reg, pred_te_bl):>11.4f} {r2_score(y_test_reg, pred_te_bl):>11.4f}')
print(f'{"Standard LSTM":<25} {rmse(y_test_reg, pred_te):>11.4f} {r2_score(y_test_reg, pred_te):>11.4f}')
print(f'{"Improved LSTM":<25} {rmse(y_test_reg, pred_te_improved):>11.4f} {r2_score(y_test_reg, pred_te_improved):>11.4f}')
print('='*60)

# æ”¹å–„ç‡ã®è¨ˆç®—
baseline_rmse = rmse(y_test_reg, pred_te_bl)
standard_rmse = rmse(y_test_reg, pred_te)
improved_rmse = rmse(y_test_reg, pred_te_improved)

improvement_vs_baseline = ((baseline_rmse - improved_rmse) / baseline_rmse) * 100
improvement_vs_standard = ((standard_rmse - improved_rmse) / standard_rmse) * 100

print(f'\nImprovement:')
print(f'  vs Baseline: {improvement_vs_baseline:+.2f}%')
print(f'  vs Standard LSTM: {improvement_vs_standard:+.2f}%')

# === å­¦ç¿’æ›²ç·šã®æ¯”è¼ƒå¯è¦–åŒ– ===
fig, axes = plt.subplots(2, 3, figsize=(18, 10))

# 1. æ¨™æº–LSTMã®å­¦ç¿’æ›²ç·š
ax1 = axes[0, 0]
ax1.plot(hist.history['loss'], label='Train Loss', linewidth=2, color='blue')
ax1.plot(hist.history['val_loss'], label='Val Loss', linewidth=2, color='orange')
min_val_loss_epoch = np.argmin(hist.history['val_loss'])
min_val_loss = hist.history['val_loss'][min_val_loss_epoch]
ax1.plot(min_val_loss_epoch, min_val_loss, 'r*', markersize=15)
ax1.set_title('Standard LSTM Training', fontsize=12, fontweight='bold')
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Loss (MSE)')
ax1.legend()
ax1.grid(True, alpha=0.3)

# 2. æ”¹è‰¯LSTMã®å­¦ç¿’æ›²ç·š
ax2 = axes[0, 1]
ax2.plot(hist_improved.history['loss'], label='Train Loss', linewidth=2, color='blue')
ax2.plot(hist_improved.history['val_loss'], label='Val Loss', linewidth=2, color='orange')
min_val_loss_epoch_imp = np.argmin(hist_improved.history['val_loss'])
min_val_loss_imp = hist_improved.history['val_loss'][min_val_loss_epoch_imp]
ax2.plot(min_val_loss_epoch_imp, min_val_loss_imp, 'r*', markersize=15)
ax2.set_title('Improved LSTM Training', fontsize=12, fontweight='bold')
ax2.set_xlabel('Epoch')
ax2.set_ylabel('Loss (Huber)')
ax2.legend()
ax2.grid(True, alpha=0.3)

# 3. ä¸¡æ–¹ã®å­¦ç¿’æ›²ç·šã‚’é‡ã­ã¦æ¯”è¼ƒ
ax3 = axes[0, 2]
ax3.plot(hist.history['val_loss'], label='Standard LSTM', linewidth=2, color='blue', alpha=0.7)
ax3.plot(hist_improved.history['val_loss'], label='Improved LSTM', linewidth=2, color='green', alpha=0.7)
ax3.set_title('Validation Loss Comparison', fontsize=12, fontweight='bold')
ax3.set_xlabel('Epoch')
ax3.set_ylabel('Loss')
ax3.legend()
ax3.grid(True, alpha=0.3)

# 4. äºˆæ¸¬å€¤ vs å®Ÿéš›å€¤ï¼ˆæ¨™æº–LSTMï¼‰
ax4 = axes[1, 0]
ax4.scatter(y_test_reg, pred_te, alpha=0.5, s=20, color='blue', label='Standard LSTM')
ax4.plot([y_test_reg.min(), y_test_reg.max()], 
         [y_test_reg.min(), y_test_reg.max()], 
         'r--', linewidth=2, label='Perfect Prediction')
ax4.set_title('Standard LSTM: Actual vs Predicted', fontsize=12, fontweight='bold')
ax4.set_xlabel('Actual Close Price')
ax4.set_ylabel('Predicted Close Price')
ax4.legend()
ax4.grid(True, alpha=0.3)

# 5. äºˆæ¸¬å€¤ vs å®Ÿéš›å€¤ï¼ˆæ”¹è‰¯LSTMï¼‰
ax5 = axes[1, 1]
ax5.scatter(y_test_reg, pred_te_improved, alpha=0.5, s=20, color='green', label='Improved LSTM')
ax5.plot([y_test_reg.min(), y_test_reg.max()], 
         [y_test_reg.min(), y_test_reg.max()], 
         'r--', linewidth=2, label='Perfect Prediction')
ax5.set_title('Improved LSTM: Actual vs Predicted', fontsize=12, fontweight='bold')
ax5.set_xlabel('Actual Close Price')
ax5.set_ylabel('Predicted Close Price')
ax5.legend()
ax5.grid(True, alpha=0.3)

# 6. äºˆæ¸¬èª¤å·®ã®åˆ†å¸ƒæ¯”è¼ƒ
ax6 = axes[1, 2]
errors_standard = y_test_reg - pred_te
errors_improved = y_test_reg - pred_te_improved
ax6.hist(errors_standard, bins=20, alpha=0.5, label='Standard LSTM', color='blue', edgecolor='black')
ax6.hist(errors_improved, bins=20, alpha=0.5, label='Improved LSTM', color='green', edgecolor='black')
ax6.axvline(0, color='red', linestyle='--', linewidth=2)
ax6.set_title('Prediction Error Distribution', fontsize=12, fontweight='bold')
ax6.set_xlabel('Error (Actual - Predicted)')
ax6.set_ylabel('Frequency')
ax6.legend()
ax6.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("\nImproved model training and comparison complete!")


# In[ ]:


# === æ”¹è‰¯ç‰ˆãƒ¢ãƒ‡ãƒ«ã§ã®åˆ†é¡ãƒ»ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ ===
print('\n' + '='*70)
print('Improved Model: Buy/Sell Classification & Backtest')
print('='*70)

# å¿…è¦ãªå¤‰æ•°ã‚’ç¢ºèªï¼ˆåˆ†é¡ã‚»ãƒ«ã§å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã¯ãšï¼‰
if 'close_test_tail' not in dir():
    print('âš ï¸  Warning: close_test_tail not found. Please run the classification cell first.')
    print('   Skipping improved model evaluation.')
else:
    # Buy/Sellåˆ¤å®šï¼ˆæ”¹è‰¯ç‰ˆãƒ¢ãƒ‡ãƒ«ï¼‰
    buy_pred_te_improved = (pred_te_improved > close_test_tail).astype(int)

    # åˆ†é¡æ€§èƒ½
    metrics_te_improved = cls_metrics(y_test_cls, buy_pred_te_improved)

    print('\nåˆ†é¡æ€§èƒ½æ¯”è¼ƒ:')
    print(f'{"Model":<20} {"Accuracy":<12} {"Precision":<12} {"Recall":<12} {"F1":<12}')
    print('-'*70)
    print(f'{"Standard LSTM":<20} {metrics_te["acc"]:>11.4f} {metrics_te["prec"]:>11.4f} {metrics_te["rec"]:>11.4f} {metrics_te["f1"]:>11.4f}')
    print(f'{"Improved LSTM":<20} {metrics_te_improved["acc"]:>11.4f} {metrics_te_improved["prec"]:>11.4f} {metrics_te_improved["rec"]:>11.4f} {metrics_te_improved["f1"]:>11.4f}')

    # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰
    ret_improved = np.zeros_like(buy_pred_te_improved, dtype=float)
    ret_improved[buy_pred_te_improved == 1] = price_diff[buy_pred_te_improved == 1]
    cum_ret_improved = (1 + ret_improved).cumprod() - 1

    print('\nãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ¯”è¼ƒ:')
    print(f'{"Model":<20} {"Final Return":<15} {"# Trades":<12} {"Win Rate":<12}')
    print('-'*70)

    # æ¨™æº–LSTMã®çµ±è¨ˆ
    n_trades_standard = buy_pred_te.sum()
    if n_trades_standard > 0:
        trade_returns_standard = ret[buy_pred_te == 1]
        wins_standard = (trade_returns_standard > 0).sum()
        win_rate_standard = wins_standard / n_trades_standard
    else:
        win_rate_standard = 0

    # æ”¹è‰¯LSTMã®çµ±è¨ˆ
    n_trades_improved = buy_pred_te_improved.sum()
    if n_trades_improved > 0:
        trade_returns_improved = ret_improved[buy_pred_te_improved == 1]
        wins_improved = (trade_returns_improved > 0).sum()
        win_rate_improved = wins_improved / n_trades_improved
    else:
        win_rate_improved = 0

    print(f'{"Standard LSTM":<20} {cum_ret[-1]:>14.2%} {n_trades_standard:>11} {win_rate_standard:>11.2%}')
    print(f'{"Improved LSTM":<20} {cum_ret_improved[-1]:>14.2%} {n_trades_improved:>11} {win_rate_improved:>11.2%}')
    print(f'{"Buy & Hold":<20} {buy_hold_ret_aligned[-1]:>14.2%} {"-":>11} {"-":>11}')

    # === å¯è¦–åŒ–ï¼šãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ¯”è¼ƒ ===
    fig, axes = plt.subplots(2, 2, figsize=(16, 10))

    # 1. ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ã®æ¯”è¼ƒ
    ax1 = axes[0, 0]
    ax1.plot(cum_ret, label='Standard LSTM', linewidth=2, color='blue')
    ax1.plot(cum_ret_improved, label='Improved LSTM', linewidth=2, color='green')
    ax1.plot(buy_hold_ret_aligned, label='Buy & Hold', linewidth=2, color='gray', linestyle='--')
    ax1.axhline(0, color='k', linestyle='-', linewidth=0.5, alpha=0.5)
    ax1.set_title('Cumulative Returns Comparison', fontsize=12, fontweight='bold')
    ax1.set_xlabel('Trading Days')
    ax1.set_ylabel('Cumulative Return')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # æœ€çµ‚ãƒªã‚¿ãƒ¼ãƒ³ã‚’è¡¨ç¤º
    final_returns_text = f'Standard: {cum_ret[-1]:.2%}\nImproved: {cum_ret_improved[-1]:.2%}\nB&H: {buy_hold_ret_aligned[-1]:.2%}'
    ax1.text(0.02, 0.98, final_returns_text,
             transform=ax1.transAxes, fontsize=10, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    # 2. Buyä¿¡å·ã®å‰²åˆæ¯”è¼ƒ
    ax2 = axes[0, 1]
    models = ['Actual', 'Standard\nLSTM', 'Improved\nLSTM']
    buy_ratios = [
        y_test_cls.mean(),
        buy_pred_te.mean(),
        buy_pred_te_improved.mean()
    ]
    colors = ['gray', 'blue', 'green']
    bars = ax2.bar(models, buy_ratios, color=colors, alpha=0.7)
    for bar in bars:
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.1%}', ha='center', va='bottom', fontsize=10)
    ax2.set_ylabel('Buy Signal Ratio')
    ax2.set_title('Buy Signal Distribution', fontsize=12, fontweight='bold')
    ax2.set_ylim(0, 1.0)
    ax2.grid(True, alpha=0.3, axis='y')

    # 3. Confusion Matrixæ¯”è¼ƒï¼ˆæ¨™æº–LSTMï¼‰
    ax3 = axes[1, 0]
    cm_standard = confusion_matrix(y_test_cls, buy_pred_te)
    from sklearn.metrics import ConfusionMatrixDisplay
    disp_standard = ConfusionMatrixDisplay(confusion_matrix=cm_standard, display_labels=['Sell', 'Buy'])
    disp_standard.plot(ax=ax3, cmap='Blues', values_format='d')
    ax3.set_title('Standard LSTM: Confusion Matrix', fontsize=12, fontweight='bold')

    # 4. Confusion Matrixæ¯”è¼ƒï¼ˆæ”¹è‰¯LSTMï¼‰
    ax4 = axes[1, 1]
    cm_improved = confusion_matrix(y_test_cls, buy_pred_te_improved)
    disp_improved = ConfusionMatrixDisplay(confusion_matrix=cm_improved, display_labels=['Sell', 'Buy'])
    disp_improved.plot(ax=ax4, cmap='Greens', values_format='d')
    ax4.set_title('Improved LSTM: Confusion Matrix', fontsize=12, fontweight='bold')

    plt.tight_layout()
    plt.show()

    # === è©³ç´°ãªçµ±è¨ˆæ¯”è¼ƒ ===
    print('\n' + '='*70)
    print('Detailed Statistics Comparison')
    print('='*70)

    print('\nã€äºˆæ¸¬ãƒã‚¤ã‚¢ã‚¹ã€‘')
    print(f'  Standard LSTM: å¹³å‡äºˆæ¸¬å·® = {(pred_te - close_test_tail).mean():+.4f}')
    print(f'  Improved LSTM: å¹³å‡äºˆæ¸¬å·® = {(pred_te_improved - close_test_tail).mean():+.4f}')
    print(f'  (æ­£ã®å€¤ = æ¥½è¦³çš„, è² ã®å€¤ = æ‚²è¦³çš„)')

    print('\nã€Buyä¿¡å·ã®ç²¾åº¦ã€‘')
    print(f'  å®Ÿéš›ã®Buyå‰²åˆ: {y_test_cls.mean():.1%}')
    print(f'  Standardäºˆæ¸¬: {buy_pred_te.mean():.1%} (å·®åˆ†: {(buy_pred_te.mean() - y_test_cls.mean())*100:+.1f}%)')
    print(f'  Improvedäºˆæ¸¬: {buy_pred_te_improved.mean():.1%} (å·®åˆ†: {(buy_pred_te_improved.mean() - y_test_cls.mean())*100:+.1f}%)')

    print('\nã€ãƒˆãƒ¬ãƒ¼ãƒ‰çµ±è¨ˆã€‘')
    if n_trades_standard > 0:
        print(f'  Standard LSTM:')
        print(f'    ãƒˆãƒ¬ãƒ¼ãƒ‰æ•°: {n_trades_standard}')
        print(f'    å‹ç‡: {win_rate_standard:.2%}')
        print(f'    å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³: {trade_returns_standard.mean():.4f}')

    if n_trades_improved > 0:
        print(f'  Improved LSTM:')
        print(f'    ãƒˆãƒ¬ãƒ¼ãƒ‰æ•°: {n_trades_improved}')
        print(f'    å‹ç‡: {win_rate_improved:.2%}')
        print(f'    å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³: {trade_returns_improved.mean():.4f}')

    print('='*70)
    print('\nâœ“ Improved model evaluation complete!')


# In[ ]:


# === åˆ†é¡ï¼šäºˆæ¸¬çµ‚å€¤ã«åŸºã¥ã Buy(1)/Sell(0) åˆ¤å®š ===
# åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼š pred_close_{t+1} > actual_close_{t} ? 1 : 0
# æ™‚ç³»åˆ—æ•´åˆã®ãŸã‚ã€å„ã‚»ãƒƒãƒˆã®åŸºæº– day_t ã® close å®Ÿå€¤ã‚’æº–å‚™ã™ã‚‹

def get_last_close_vector(df_part, window):
    # å„ã‚µãƒ³ãƒ—ãƒ«ã® "ç›´è¿‘æ—¥ã®å®ŸClose" ã‚’å–ã‚Šå‡ºã™ (ãƒ©ãƒ™ãƒ«ç”Ÿæˆç”¨)
    vals = df_part['close'].values  # *ã‚¹ã‚±ãƒ¼ãƒ«å‰* ãŒæœ¬æ¥æœ›ã¾ã—ã„ãŒã€ã“ã“ã¯ y ã¨æ¯”è¼ƒã™ã‚‹ã ã‘ãªã®ã§ OK
    # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§åˆ‡ã£ãŸæœ€å¾Œã®è¡Œã® index ã‚’å¯¾å¿œã¥ã‘
    out = []
    for i in range(len(df_part) - window):
        out.append(vals[i + window - 1])
    return np.array(out)

close_train_tail = get_last_close_vector(train, WINDOW_SIZE)
close_val_tail   = get_last_close_vector(val,   WINDOW_SIZE)
close_test_tail  = get_last_close_vector(test,  WINDOW_SIZE)

buy_pred_tr = (pred_tr > close_train_tail).astype(int)
buy_pred_v  = (pred_v  > close_val_tail).astype(int)
buy_pred_te = (pred_te > close_test_tail).astype(int)

print('='*60)
print('Classification Metrics (Buy=1 / Sell=0)')
print('='*60)

def cls_metrics(y_true, y_pred):
    return {
        'acc': accuracy_score(y_true, y_pred),
        'prec': precision_score(y_true, y_pred, zero_division=0),
        'rec': recall_score(y_true, y_pred, zero_division=0),
        'f1': f1_score(y_true, y_pred, zero_division=0),
    }

metrics_tr = cls_metrics(y_train_cls, buy_pred_tr)
metrics_v = cls_metrics(y_val_cls, buy_pred_v)
metrics_te = cls_metrics(y_test_cls, buy_pred_te)

print(f'Train: Acc={metrics_tr["acc"]:.4f}, Prec={metrics_tr["prec"]:.4f}, Rec={metrics_tr["rec"]:.4f}, F1={metrics_tr["f1"]:.4f}')
print(f'Val:   Acc={metrics_v["acc"]:.4f}, Prec={metrics_v["prec"]:.4f}, Rec={metrics_v["rec"]:.4f}, F1={metrics_v["f1"]:.4f}')
print(f'Test:  Acc={metrics_te["acc"]:.4f}, Prec={metrics_te["prec"]:.4f}, Rec={metrics_te["rec"]:.4f}, F1={metrics_te["f1"]:.4f}')
print('='*60)

# Confusion Matrix (Test)
cm = confusion_matrix(y_test_cls, buy_pred_te)
print('\nConfusion Matrix (Test)')
print(cm)
print('\nClassification Report (Test)')
print(classification_report(y_test_cls, buy_pred_te, zero_division=0, target_names=['Sell (0)', 'Buy (1)']))

# === åˆ†é¡æ€§èƒ½ã®è©³ç´°å¯è¦–åŒ– ===
fig, axes = plt.subplots(2, 3, figsize=(18, 10))

# 1. Confusion Matrix (Train)
from sklearn.metrics import ConfusionMatrixDisplay
cm_train = confusion_matrix(y_train_cls, buy_pred_tr)
disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=['Sell', 'Buy'])
disp_train.plot(ax=axes[0, 0], cmap='Blues', values_format='d')
axes[0, 0].set_title('Train: Confusion Matrix', fontsize=12, fontweight='bold')

# 2. Confusion Matrix (Val)
cm_val = confusion_matrix(y_val_cls, buy_pred_v)
disp_val = ConfusionMatrixDisplay(confusion_matrix=cm_val, display_labels=['Sell', 'Buy'])
disp_val.plot(ax=axes[0, 1], cmap='Oranges', values_format='d')
axes[0, 1].set_title('Val: Confusion Matrix', fontsize=12, fontweight='bold')

# 3. Confusion Matrix (Test)
cm_test = confusion_matrix(y_test_cls, buy_pred_te)
disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=['Sell', 'Buy'])
disp_test.plot(ax=axes[0, 2], cmap='Greens', values_format='d')
axes[0, 2].set_title('Test: Confusion Matrix', fontsize=12, fontweight='bold')

# 4. ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ¯”è¼ƒï¼ˆTrain/Val/Testï¼‰
splits = ['Train', 'Val', 'Test']
metrics_list = [metrics_tr, metrics_v, metrics_te]

metric_names = ['acc', 'prec', 'rec', 'f1']
metric_labels = ['Accuracy', 'Precision', 'Recall', 'F1-Score']

for idx, (metric_name, metric_label) in enumerate(zip(metric_names, metric_labels)):
    ax = axes[1, idx] if idx < 3 else None
    if ax is None:
        continue

    values = [m[metric_name] for m in metrics_list]
    bars = ax.bar(splits, values, color=['blue', 'orange', 'green'], alpha=0.7)

    # ãƒãƒ¼ã®ä¸Šã«å€¤ã‚’è¡¨ç¤º
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.3f}', ha='center', va='bottom', fontsize=10)

    ax.set_ylabel(metric_label)
    ax.set_title(f'{metric_label} by Split', fontsize=12, fontweight='bold')
    ax.set_ylim(0, 1.1)
    ax.grid(True, alpha=0.3, axis='y')

# 5. äºˆæ¸¬ä¿¡é ¼åº¦åˆ†å¸ƒï¼ˆTest: äºˆæ¸¬çµ‚å€¤ - ç¾åœ¨çµ‚å€¤ã®å·®åˆ†ï¼‰
if len(axes[1]) > 3:
    axes[1, 3].remove()

plt.tight_layout()
plt.show()

# === äºˆæ¸¬ã®ä¿¡é ¼åº¦åˆ†æ ===
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# TestæœŸé–“ã®äºˆæ¸¬å·®åˆ†ï¼ˆäºˆæ¸¬çµ‚å€¤ - ç¾åœ¨çµ‚å€¤ï¼‰
pred_diff = pred_te - close_test_tail

# 1. Buy/Sellåˆ¥ã®äºˆæ¸¬å·®åˆ†åˆ†å¸ƒ
ax1 = axes[0]
buy_mask = buy_pred_te == 1
sell_mask = buy_pred_te == 0

ax1.hist(pred_diff[buy_mask], bins=30, alpha=0.6, label='Buy Predictions', color='green', edgecolor='black')
ax1.hist(pred_diff[sell_mask], bins=30, alpha=0.6, label='Sell Predictions', color='red', edgecolor='black')
ax1.axvline(0, color='black', linestyle='--', linewidth=2, label='No Change')
ax1.set_title('Prediction Confidence Distribution', fontsize=12, fontweight='bold')
ax1.set_xlabel('Predicted Price Change')
ax1.set_ylabel('Frequency')
ax1.legend()
ax1.grid(True, alpha=0.3)

# 2. æ­£è§£/ä¸æ­£è§£åˆ¥ã®äºˆæ¸¬å·®åˆ†åˆ†å¸ƒ
ax2 = axes[1]
correct_mask = (buy_pred_te == y_test_cls).astype(bool)
incorrect_mask = ~correct_mask

ax2.hist(np.abs(pred_diff[correct_mask]), bins=30, alpha=0.6, label='Correct Predictions', 
         color='blue', edgecolor='black')
ax2.hist(np.abs(pred_diff[incorrect_mask]), bins=30, alpha=0.6, label='Incorrect Predictions', 
         color='orange', edgecolor='black')
ax2.set_title('Prediction Magnitude: Correct vs Incorrect', fontsize=12, fontweight='bold')
ax2.set_xlabel('|Predicted Price Change|')
ax2.set_ylabel('Frequency')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("\nClassification visualization complete!")


# In[ ]:


# === äºˆæ¸¬çµæœã®è©³ç´°å¯è¦–åŒ– ===
fig, axes = plt.subplots(3, 2, figsize=(16, 12))

# 1. Train: å®Ÿéš›ã®å€¤ vs äºˆæ¸¬å€¤ï¼ˆæ•£å¸ƒå›³ï¼‰
ax1 = axes[0, 0]
ax1.scatter(y_train_reg, pred_tr, alpha=0.3, s=10, color='blue')
ax1.plot([y_train_reg.min(), y_train_reg.max()], 
         [y_train_reg.min(), y_train_reg.max()], 
         'r--', linewidth=2, label='Perfect Prediction')
ax1.set_title('Train: Actual vs Predicted', fontsize=12, fontweight='bold')
ax1.set_xlabel('Actual Close Price')
ax1.set_ylabel('Predicted Close Price')
ax1.legend()
ax1.grid(True, alpha=0.3)

# R2ã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤º
r2_train = r2_score(y_train_reg, pred_tr)
ax1.text(0.05, 0.95, f'RÂ² = {r2_train:.4f}\nRMSE = {rmse(y_train_reg, pred_tr):.4f}',
         transform=ax1.transAxes, fontsize=10, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

# 2. Val: å®Ÿéš›ã®å€¤ vs äºˆæ¸¬å€¤
ax2 = axes[0, 1]
ax2.scatter(y_val_reg, pred_v, alpha=0.5, s=20, color='orange')
ax2.plot([y_val_reg.min(), y_val_reg.max()], 
         [y_val_reg.min(), y_val_reg.max()], 
         'r--', linewidth=2, label='Perfect Prediction')
ax2.set_title('Val: Actual vs Predicted', fontsize=12, fontweight='bold')
ax2.set_xlabel('Actual Close Price')
ax2.set_ylabel('Predicted Close Price')
ax2.legend()
ax2.grid(True, alpha=0.3)

r2_val = r2_score(y_val_reg, pred_v)
ax2.text(0.05, 0.95, f'RÂ² = {r2_val:.4f}\nRMSE = {rmse(y_val_reg, pred_v):.4f}',
         transform=ax2.transAxes, fontsize=10, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

# 3. Test: å®Ÿéš›ã®å€¤ vs äºˆæ¸¬å€¤
ax3 = axes[1, 0]
ax3.scatter(y_test_reg, pred_te, alpha=0.5, s=20, color='green')
ax3.plot([y_test_reg.min(), y_test_reg.max()], 
         [y_test_reg.min(), y_test_reg.max()], 
         'r--', linewidth=2, label='Perfect Prediction')
ax3.set_title('Test: Actual vs Predicted', fontsize=12, fontweight='bold')
ax3.set_xlabel('Actual Close Price')
ax3.set_ylabel('Predicted Close Price')
ax3.legend()
ax3.grid(True, alpha=0.3)

r2_test = r2_score(y_test_reg, pred_te)
ax3.text(0.05, 0.95, f'RÂ² = {r2_test:.4f}\nRMSE = {rmse(y_test_reg, pred_te):.4f}',
         transform=ax3.transAxes, fontsize=10, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

# 4. äºˆæ¸¬èª¤å·®ã®åˆ†å¸ƒï¼ˆTestï¼‰
ax4 = axes[1, 1]
errors = y_test_reg - pred_te
ax4.hist(errors, bins=30, color='purple', alpha=0.7, edgecolor='black')
ax4.axvline(0, color='red', linestyle='--', linewidth=2, label='Zero Error')
ax4.axvline(errors.mean(), color='green', linestyle='--', linewidth=2, 
            label=f'Mean Error: {errors.mean():.4f}')
ax4.set_title('Test: Prediction Error Distribution', fontsize=12, fontweight='bold')
ax4.set_xlabel('Error (Actual - Predicted)')
ax4.set_ylabel('Frequency')
ax4.legend()
ax4.grid(True, alpha=0.3)

# 5. TestæœŸé–“ã®æ™‚ç³»åˆ—äºˆæ¸¬ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼šæœ€åˆã®100æ—¥ï¼‰
ax5 = axes[2, 0]
n_show = min(100, len(y_test_reg))
indices = range(n_show)
ax5.plot(indices, y_test_reg[:n_show], label='Actual', linewidth=2, color='blue', marker='o', markersize=3)
ax5.plot(indices, pred_te[:n_show], label='Predicted', linewidth=2, color='red', marker='x', markersize=3)
ax5.set_title(f'Test: Time Series Prediction (First {n_show} days)', fontsize=12, fontweight='bold')
ax5.set_xlabel('Sample Index')
ax5.set_ylabel('Close Price')
ax5.legend()
ax5.grid(True, alpha=0.3)

# 6. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ vs LSTMæ¯”è¼ƒï¼ˆRMSEï¼‰
ax6 = axes[2, 1]
models = ['Baseline\n(Linear Reg)', 'LSTM']
train_rmses = [rmse(y_train_reg, pred_tr_bl), rmse(y_train_reg, pred_tr)]
val_rmses = [rmse(y_val_reg, pred_v_bl), rmse(y_val_reg, pred_v)]
test_rmses = [rmse(y_test_reg, pred_te_bl), rmse(y_test_reg, pred_te)]

x = np.arange(len(models))
width = 0.25

bars1 = ax6.bar(x - width, train_rmses, width, label='Train', color='blue', alpha=0.7)
bars2 = ax6.bar(x, val_rmses, width, label='Val', color='orange', alpha=0.7)
bars3 = ax6.bar(x + width, test_rmses, width, label='Test', color='green', alpha=0.7)

# ãƒãƒ¼ã®ä¸Šã«å€¤ã‚’è¡¨ç¤º
for bars in [bars1, bars2, bars3]:
    for bar in bars:
        height = bar.get_height()
        ax6.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.3f}', ha='center', va='bottom', fontsize=9)

ax6.set_ylabel('RMSE')
ax6.set_title('Model Comparison: RMSE', fontsize=12, fontweight='bold')
ax6.set_xticks(x)
ax6.set_xticklabels(models)
ax6.legend()
ax6.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()

print("\nPrediction visualization complete!")


# In[ ]:


# === ã‚·ãƒ³ãƒ—ãƒ«ãƒ»ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼ˆãƒ†ã‚¹ãƒˆåŒºé–“ã®ã¿ï¼‰ ===
# ãƒ«ãƒ¼ãƒ«ï¼š
#   Buy(1) -> ç¿Œæ—¥å¯„ã‚Šã§è²·ã£ã¦ç¿Œæ—¥å¼•ã‘ã§æ‰‹ä»•èˆã„ï¼ˆ= ç¿Œæ—¥çµ‚å€¤ã¨å½“æ—¥çµ‚å€¤ã®å·®åˆ†ã«é€£å‹•ã™ã‚‹ã¨ä»®å®šï¼‰
#   Sell(0) -> ä½•ã‚‚ã—ãªã„ï¼ˆç©ºå£²ã‚Šç­‰ã¯è€ƒæ…®ã—ãªã„ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰

test_close = test['close'].values
# ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åˆ‡ã‚Šè©°ã‚ã«åˆã‚ã›ã¦ test_close ã‚’æœ«å°¾1æ—¥åˆ†å‰Šã‚‹ï¼ˆy_test_reg ã¨é•·ã•ä¸€è‡´ï¼‰
test_close_tail = test_close[WINDOW_SIZE-1: -1]  # day_t close
test_close_next = test_close[WINDOW_SIZE:]       # day_{t+1} close

# åç›Šç‡ï¼ˆBuyã®ã¨ãã®ã¿ãƒªã‚¿ãƒ¼ãƒ³ã‚’è¨ˆä¸Šï¼‰
ret = np.zeros_like(buy_pred_te, dtype=float)
price_diff = (test_close_next - test_close_tail) / (test_close_tail + 1e-9)  # æ—¥æ¬¡é¨°è½ç‡
ret[buy_pred_te == 1] = price_diff[buy_pred_te == 1]

cum_ret = (1 + ret).cumprod() - 1

# Buy and Holdã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
buy_hold_ret = (test_close - test_close[0]) / test_close[0]
buy_hold_ret_aligned = buy_hold_ret[WINDOW_SIZE:]  # é•·ã•ã‚’åˆã‚ã›ã‚‹

print('='*60)
print('Backtest Results (Test Period)')
print('='*60)
print(f'Final Cumulative Return (Strategy): {cum_ret[-1]:.2%}')
print(f'Final Cumulative Return (Buy & Hold): {buy_hold_ret_aligned[-1]:.2%}')
print(f'Number of Trades (Buy signals): {buy_pred_te.sum()}')
print(f'Win Rate: {((ret > 0) & (buy_pred_te == 1)).sum() / max(buy_pred_te.sum(), 1):.2%}')
print(f'Average Return per Trade: {ret[buy_pred_te == 1].mean():.4f} ({ret[buy_pred_te == 1].mean()*100:.2f}%)')
print(f'Sharpe Ratio (approx): {(ret.mean() / (ret.std() + 1e-9)) * np.sqrt(252):.2f}')
print('='*60)

# === ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã®è©³ç´°å¯è¦–åŒ– ===
fig, axes = plt.subplots(3, 2, figsize=(16, 12))

# 1. ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆStrategy vs Buy & Holdï¼‰
ax1 = axes[0, 0]
ax1.plot(cum_ret, label='Strategy (Buy on predicted up)', linewidth=2, color='blue')
ax1.plot(buy_hold_ret_aligned, label='Buy & Hold', linewidth=2, color='gray', linestyle='--')
ax1.axhline(0, color='k', linestyle='-', linewidth=0.5, alpha=0.5)
ax1.set_title('Cumulative Return Comparison', fontsize=12, fontweight='bold')
ax1.set_xlabel('Trading Days')
ax1.set_ylabel('Cumulative Return')
ax1.legend()
ax1.grid(True, alpha=0.3)

# æœ€çµ‚ãƒªã‚¿ãƒ¼ãƒ³ã‚’è¡¨ç¤º
ax1.text(0.02, 0.98, f'Strategy: {cum_ret[-1]:.2%}\nBuy & Hold: {buy_hold_ret_aligned[-1]:.2%}',
         transform=ax1.transAxes, fontsize=10, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

# 2. æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³ã®åˆ†å¸ƒ
ax2 = axes[0, 1]
ax2.hist(ret, bins=50, color='purple', alpha=0.7, edgecolor='black')
ax2.axvline(ret.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {ret.mean():.4f}')
ax2.axvline(0, color='black', linestyle='-', linewidth=1)
ax2.set_title('Daily Returns Distribution', fontsize=12, fontweight='bold')
ax2.set_xlabel('Daily Return')
ax2.set_ylabel('Frequency')
ax2.legend()
ax2.grid(True, alpha=0.3)

# 3. ãƒˆãƒ¬ãƒ¼ãƒ‰å‹ç‡ï¼ˆBuyä¿¡å·ã®ã¿ï¼‰
ax3 = axes[1, 0]
trade_returns = ret[buy_pred_te == 1]
wins = (trade_returns > 0).sum()
losses = (trade_returns <= 0).sum()
ax3.bar(['Wins', 'Losses'], [wins, losses], color=['green', 'red'], alpha=0.7)
ax3.set_title('Trade Outcome (Buy Signals Only)', fontsize=12, fontweight='bold')
ax3.set_ylabel('Count')
for i, (label, val) in enumerate([('Wins', wins), ('Losses', losses)]):
    ax3.text(i, val, f'{val}\n({val/(wins+losses)*100:.1f}%)', 
             ha='center', va='bottom', fontsize=10)
ax3.grid(True, alpha=0.3, axis='y')

# 4. å‹ã¡ãƒˆãƒ¬ãƒ¼ãƒ‰ã¨è² ã‘ãƒˆãƒ¬ãƒ¼ãƒ‰ã®å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³
ax4 = axes[1, 1]
win_returns = trade_returns[trade_returns > 0]
loss_returns = trade_returns[trade_returns <= 0]
avg_win = win_returns.mean() if len(win_returns) > 0 else 0
avg_loss = loss_returns.mean() if len(loss_returns) > 0 else 0
ax4.bar(['Avg Win', 'Avg Loss'], [avg_win, avg_loss], color=['green', 'red'], alpha=0.7)
ax4.axhline(0, color='black', linestyle='-', linewidth=0.5)
ax4.set_title('Average Return per Trade Type', fontsize=12, fontweight='bold')
ax4.set_ylabel('Average Return')
for i, (label, val) in enumerate([('Avg Win', avg_win), ('Avg Loss', avg_loss)]):
    ax4.text(i, val, f'{val:.4f}\n({val*100:.2f}%)', 
             ha='center', va='bottom' if val > 0 else 'top', fontsize=10)
ax4.grid(True, alpha=0.3, axis='y')

# 5. ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³åˆ†æ
ax5 = axes[2, 0]
cum_ret_series = pd.Series(cum_ret)
running_max = cum_ret_series.cummax()
drawdown = cum_ret_series - running_max
ax5.fill_between(range(len(drawdown)), 0, drawdown, color='red', alpha=0.3, label='Drawdown')
ax5.plot(drawdown, color='red', linewidth=1)
ax5.set_title('Drawdown Analysis', fontsize=12, fontweight='bold')
ax5.set_xlabel('Trading Days')
ax5.set_ylabel('Drawdown')
ax5.legend()
ax5.grid(True, alpha=0.3)

max_dd = drawdown.min()
ax5.text(0.02, 0.02, f'Max Drawdown: {max_dd:.2%}',
         transform=ax5.transAxes, fontsize=10, verticalalignment='bottom',
         bbox=dict(boxstyle='round', facecolor='pink', alpha=0.5))

# 6. æœˆåˆ¥ãƒªã‚¿ãƒ¼ãƒ³åˆ†æ
ax6 = axes[2, 1]
# TestæœŸé–“ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
test_indices = test.index[WINDOW_SIZE:]
if len(test_indices) == len(ret):
    ret_series = pd.Series(ret, index=test_indices)
    monthly_ret = ret_series.resample('M').sum()
    colors = ['green' if x > 0 else 'red' for x in monthly_ret]
    ax6.bar(range(len(monthly_ret)), monthly_ret.values, color=colors, alpha=0.7)
    ax6.axhline(0, color='black', linestyle='-', linewidth=0.5)
    ax6.set_title('Monthly Returns', fontsize=12, fontweight='bold')
    ax6.set_xlabel('Month Index')
    ax6.set_ylabel('Monthly Return')
    ax6.grid(True, alpha=0.3, axis='y')
else:
    ax6.text(0.5, 0.5, 'Monthly returns\nnot available\n(index mismatch)',
             transform=ax6.transAxes, fontsize=12, ha='center', va='center')
    ax6.axis('off')

plt.tight_layout()
plt.show()

print("\nBacktest visualization complete!")


# In[ ]:


# === ä¿å­˜ç‰© ===
joblib.dump(scaler_X, 'scaler_X_7203T.joblib')
joblib.dump(scaler_y, 'scaler_y_7203T.joblib')
model_reg.save('model_regression_7203T.keras')

with open('params_7203T.txt', 'w', encoding='utf-8') as f:
    f.write(f'Ticker: {TICKER}\n')
    f.write(f'Period: {START_DATE}..{END_DATE}\n')
    f.write(f'Window: {WINDOW_SIZE}\n')
    f.write(f'Train end: {SPLIT_TRAIN_END}\nVal end: {SPLIT_VAL_END}\n')
    f.write(f'\nScalers:\n')
    f.write(f'  scaler_X: Feature scaler (StandardScaler)\n')
    f.write(f'  scaler_y: Target scaler (StandardScaler)\n')
    f.write(f'\nModel Performance:\n')
    f.write(f'  Test RMSE: {rmse(y_test_reg, pred_te):.4f}\n')
    f.write(f'  Test RÂ²: {r2_score(y_test_reg, pred_te):.4f}\n')

print('Artifacts saved:')
print('  - scaler_X_7203T.joblib (feature scaler)')
print('  - scaler_y_7203T.joblib (target scaler)')
print('  - model_regression_7203T.keras (trained model)')
print('  - params_7203T.txt (parameters and metrics)')


# In[ ]:


# === ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã®ç²¾åº¦ã‚µãƒãƒªãƒ¼å¯è¦–åŒ– ===
fig = plt.figure(figsize=(18, 12))
gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)

# 1. å›å¸°æ€§èƒ½ã®ç·åˆæ¯”è¼ƒï¼ˆRMSE & RÂ²ï¼‰
ax1 = fig.add_subplot(gs[0, 0])
models = ['Baseline', 'LSTM']
test_rmse_vals = [rmse(y_test_reg, pred_te_bl), rmse(y_test_reg, pred_te)]
test_r2_vals = [r2_score(y_test_reg, pred_te_bl), r2_score(y_test_reg, pred_te)]

x = np.arange(len(models))
width = 0.35
bars1 = ax1.bar(x - width/2, test_rmse_vals, width, label='RMSE', color='blue', alpha=0.7)
ax1_twin = ax1.twinx()
bars2 = ax1_twin.bar(x + width/2, test_r2_vals, width, label='RÂ²', color='green', alpha=0.7)

ax1.set_ylabel('RMSE', color='blue')
ax1_twin.set_ylabel('RÂ²', color='green')
ax1.set_title('Regression Performance (Test)', fontsize=12, fontweight='bold')
ax1.set_xticks(x)
ax1.set_xticklabels(models)
ax1.tick_params(axis='y', labelcolor='blue')
ax1_twin.tick_params(axis='y', labelcolor='green')

# å€¤ã‚’è¡¨ç¤º
for bar in bars1:
    height = bar.get_height()
    ax1.text(bar.get_x() + bar.get_width()/2., height,
            f'{height:.4f}', ha='center', va='bottom', fontsize=9)
for bar in bars2:
    height = bar.get_height()
    ax1_twin.text(bar.get_x() + bar.get_width()/2., height,
            f'{height:.4f}', ha='center', va='bottom', fontsize=9)

# 2. åˆ†é¡æ€§èƒ½ã®ç·åˆæ¯”è¼ƒ
ax2 = fig.add_subplot(gs[0, 1])
metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
train_vals = [metrics_tr['acc'], metrics_tr['prec'], metrics_tr['rec'], metrics_tr['f1']]
val_vals = [metrics_v['acc'], metrics_v['prec'], metrics_v['rec'], metrics_v['f1']]
test_vals = [metrics_te['acc'], metrics_te['prec'], metrics_te['rec'], metrics_te['f1']]

x = np.arange(len(metric_names))
width = 0.25
ax2.bar(x - width, train_vals, width, label='Train', color='blue', alpha=0.7)
ax2.bar(x, val_vals, width, label='Val', color='orange', alpha=0.7)
ax2.bar(x + width, test_vals, width, label='Test', color='green', alpha=0.7)

ax2.set_ylabel('Score')
ax2.set_title('Classification Performance', fontsize=12, fontweight='bold')
ax2.set_xticks(x)
ax2.set_xticklabels(metric_names, rotation=45, ha='right')
ax2.set_ylim(0, 1.1)
ax2.legend()
ax2.grid(True, alpha=0.3, axis='y')

# 3. ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ€§èƒ½ã‚µãƒãƒªãƒ¼
ax3 = fig.add_subplot(gs[0, 2])
ax3.axis('off')

# ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµ±è¨ˆã‚’å–å¾—
n_trades = buy_pred_te.sum()
if n_trades > 0:
    trade_returns = ret[buy_pred_te == 1]
    wins = (trade_returns > 0).sum()
    win_rate = wins / n_trades
    avg_return = trade_returns.mean()
else:
    win_rate = 0
    avg_return = 0
    wins = 0

sharpe = (ret.mean() / (ret.std() + 1e-9)) * np.sqrt(252)

backtest_text = f"""
Backtest Summary (Test Period)
{'='*45}

Strategy Performance:
  Final Return:     {cum_ret[-1]:.2%}
  Buy & Hold:       {buy_hold_ret_aligned[-1]:.2%}
  Outperformance:   {(cum_ret[-1] - buy_hold_ret_aligned[-1]):.2%}

Trading Statistics:
  Total Trades:     {n_trades}
  Win Rate:         {win_rate:.2%}
  Wins/Losses:      {wins}/{n_trades - wins if n_trades > 0 else 0}
  Avg Return/Trade: {avg_return:.4f} ({avg_return*100:.2f}%)
  Sharpe Ratio:     {sharpe:.2f}

Max Drawdown:       {drawdown.min():.2%}
"""

color = 'green' if cum_ret[-1] > buy_hold_ret_aligned[-1] else 'red'
ax3.text(0.1, 0.5, backtest_text, fontsize=10, family='monospace',
         verticalalignment='center', 
         bbox=dict(boxstyle='round', facecolor=color, alpha=0.2))

# 4. äºˆæ¸¬å€¤ã®åˆ†å¸ƒï¼ˆTestï¼‰
ax4 = fig.add_subplot(gs[1, 0])
# binsæ•°ã‚’å‹•çš„ã«èª¿æ•´
n_bins = min(20, max(5, len(np.unique(y_test_reg)) // 2))
ax4.hist(y_test_reg, bins=n_bins, alpha=0.5, label='Actual', color='blue', edgecolor='black')
ax4.hist(pred_te, bins=n_bins, alpha=0.5, label='Predicted', color='red', edgecolor='black')
ax4.set_title('Test: Prediction Distribution', fontsize=12, fontweight='bold')
ax4.set_xlabel('Close Price')
ax4.set_ylabel('Frequency')
ax4.legend()
ax4.grid(True, alpha=0.3)

# 5. Buy/Selläºˆæ¸¬ã®åˆ†å¸ƒ
ax5 = fig.add_subplot(gs[1, 1])
actual_buy_pct = y_test_cls.mean()
pred_buy_pct = buy_pred_te.mean()

categories = ['Actual', 'Predicted']
buy_pcts = [actual_buy_pct, pred_buy_pct]
sell_pcts = [1 - actual_buy_pct, 1 - pred_buy_pct]

x = np.arange(len(categories))
width = 0.35
bars1 = ax5.bar(x - width/2, buy_pcts, width, label='Buy (1)', color='green', alpha=0.7)
bars2 = ax5.bar(x + width/2, sell_pcts, width, label='Sell (0)', color='red', alpha=0.7)

for bars in [bars1, bars2]:
    for bar in bars:
        height = bar.get_height()
        ax5.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.1%}', ha='center', va='bottom', fontsize=10)

ax5.set_ylabel('Ratio')
ax5.set_title('Test: Buy/Sell Distribution', fontsize=12, fontweight='bold')
ax5.set_xticks(x)
ax5.set_xticklabels(categories)
ax5.legend()
ax5.set_ylim(0, 1.1)
ax5.grid(True, alpha=0.3, axis='y')

# 6. å­¦ç¿’æ›²ç·šï¼ˆæœ€çµ‚ã‚¨ãƒãƒƒã‚¯ï¼‰
ax6 = fig.add_subplot(gs[1, 2])
final_epoch = len(hist.history['loss'])
epochs_range = range(1, final_epoch + 1)
ax6.plot(epochs_range, hist.history['loss'], label='Train Loss', linewidth=2, color='blue')
ax6.plot(epochs_range, hist.history['val_loss'], label='Val Loss', linewidth=2, color='orange')
min_val_loss_epoch = np.argmin(hist.history['val_loss'])
min_val_loss = hist.history['val_loss'][min_val_loss_epoch]
ax6.plot(min_val_loss_epoch + 1, min_val_loss, 'r*', markersize=15)
ax6.set_title('Training Progress', fontsize=12, fontweight='bold')
ax6.set_xlabel('Epoch')
ax6.set_ylabel('Loss (MSE)')
ax6.legend()
ax6.grid(True, alpha=0.3)
ax6.text(0.98, 0.98, f'Best Epoch: {min_val_loss_epoch + 1}\nBest Loss: {min_val_loss:.4f}',
         transform=ax6.transAxes, fontsize=9, verticalalignment='top', horizontalalignment='right',
         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))

# 7. ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ã®æ¯”è¼ƒ
ax7 = fig.add_subplot(gs[2, :])
ax7.plot(cum_ret, label='LSTM Strategy', linewidth=2, color='blue')
ax7.plot(buy_hold_ret_aligned, label='Buy & Hold', linewidth=2, color='gray', linestyle='--')
ax7.axhline(0, color='k', linestyle='-', linewidth=0.5, alpha=0.5)
ax7.fill_between(range(len(cum_ret)), 0, cum_ret, alpha=0.2, color='blue')
ax7.set_title('Cumulative Returns Comparison (Test Period)', fontsize=14, fontweight='bold')
ax7.set_xlabel('Trading Days')
ax7.set_ylabel('Cumulative Return')
ax7.legend(loc='best')
ax7.grid(True, alpha=0.3)

# æœ€çµ‚ãƒªã‚¿ãƒ¼ãƒ³ã‚’è¡¨ç¤º
final_ret_text = f'Final Returns:\nLSTM: {cum_ret[-1]:.2%}\nB&H: {buy_hold_ret_aligned[-1]:.2%}\nDiff: {(cum_ret[-1] - buy_hold_ret_aligned[-1]):.2%}'
ax7.text(0.02, 0.98, final_ret_text,
         transform=ax7.transAxes, fontsize=10, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

plt.suptitle('Model Performance Summary - Toyota Stock LSTM Prediction', 
             fontsize=16, fontweight='bold', y=0.995)
plt.show()

# === å•é¡Œè¨ºæ–­ ===
print('\n' + '='*70)
print('DIAGNOSTIC REPORT')
print('='*70)

# 1. äºˆæ¸¬å€¤ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯
print('\n1. Prediction Value Ranges:')
print(f'   Test Actual Close:     min={y_test_reg.min():.2f}, max={y_test_reg.max():.2f}, mean={y_test_reg.mean():.2f}')
print(f'   Test Predicted Close:  min={pred_te.min():.2f}, max={pred_te.max():.2f}, mean={pred_te.mean():.2f}')
print(f'   Test Current Close:    min={close_test_tail.min():.2f}, max={close_test_tail.max():.2f}, mean={close_test_tail.mean():.2f}')

# 2. Buy/Sellåˆ¤å®šã®è©³ç´°
print('\n2. Buy/Sell Decision Analysis:')
print(f'   Actual Buy signals:    {int(y_test_cls.sum())} ({y_test_cls.mean():.1%})')
print(f'   Predicted Buy signals: {int(buy_pred_te.sum())} ({buy_pred_te.mean():.1%})')
price_diff_pred = pred_te - close_test_tail
print(f'   Pred - Current Close:  min={price_diff_pred.min():.4f}, max={price_diff_pred.max():.4f}, mean={price_diff_pred.mean():.4f}')
print(f'   Buy threshold check:   {(pred_te > close_test_tail).sum()} predictions above current close')

# 3. ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚µãƒãƒªãƒ¼
print('\n3. Model Performance Summary:')
print(f'   Regression RMSE:       {rmse(y_test_reg, pred_te):.4f}')
print(f'   Regression RÂ²:         {r2_score(y_test_reg, pred_te):.4f}')
print(f'   Classification Acc:    {metrics_te["acc"]:.4f}')
print(f'   Classification F1:     {metrics_te["f1"]:.4f}')

# 4. æ¨å¥¨äº‹é …
print('\n4. Recommendations:')
if buy_pred_te.sum() == 0:
    print('   âš ï¸  WARNING: No Buy signals generated!')
    print('   - Model is predicting prices below or equal to current close')
    print('   - Possible causes:')
    print('     * Test period may have downward trend')
    print('     * Model is overly conservative')
    print('     * Feature scaling or window size needs adjustment')
    print('   - Suggested actions:')
    print('     * Increase training epochs or adjust model architecture')
    print('     * Try different window sizes (e.g., 20 or 50 instead of 30)')
    print('     * Add more diverse features or use different technical indicators')
elif buy_pred_te.mean() < 0.3:
    print('   âš ï¸  Low Buy signal rate detected')
    print('   - Model is conservative in Buy predictions')
    print('   - Consider threshold adjustment for more trading opportunities')
else:
    print('   âœ“ Buy signal rate is reasonable')

if r2_score(y_test_reg, pred_te) < 0.3:
    print('   âš ï¸  Low RÂ² score indicates poor prediction accuracy')
    print('   - Consider more training data, feature engineering, or model tuning')
elif r2_score(y_test_reg, pred_te) < 0:
    print('   âš ï¸  Negative RÂ² score - model performs worse than baseline!')
    print('   - Model is not capturing the pattern in test data')
    print('   - Test period characteristics may differ significantly from training')
else:
    print('   âœ“ Regression RÂ² is acceptable')

print('='*70)


# ## ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®æ§‹æˆ
# 
# ### ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# - ãƒ­ãƒ¼ã‚«ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç›´æ¥ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
# - æ—¥ä»˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ­£è¦åŒ–ã¨æ•°å€¤å‹ã¸ã®å¤‰æ›
# - 2020/09ã€œ2025/06ã®æœŸé–“ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
# 
# ### ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
# - ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã®è¨ˆç®—ï¼ˆRSI, MACD, ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰ã€ç§»å‹•å¹³å‡ï¼‰
# - ãƒªã‚¿ãƒ¼ãƒ³ã€å‡ºæ¥é«˜å¤‰åŒ–ç‡ãªã©ã®æ´¾ç”Ÿç‰¹å¾´é‡
# - ç¿Œæ—¥çµ‚å€¤äºˆæ¸¬ï¼ˆå›å¸°ï¼‰ã¨Buy/Sellåˆ¤å®šï¼ˆåˆ†é¡ï¼‰ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã‚’ç”Ÿæˆ
# 
# ### ãƒ¢ãƒ‡ãƒªãƒ³ã‚°
# - æ™‚ç³»åˆ—åˆ†å‰²ï¼ˆTrain/Val/Testï¼‰
# - ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼šç·šå½¢å›å¸°
# - ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼šLSTMï¼ˆå›å¸°ï¼‰â†’ åˆ†é¡ãƒ©ãƒ™ãƒ«ç”Ÿæˆ
# 
# ### è©•ä¾¡ã¨å¯è¦–åŒ–
# - å›å¸°ï¼šRMSE / RÂ²
# - åˆ†é¡ï¼šAccuracy / Precision / Recall / F1ã€Confusion Matrix
# - ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼šç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ã€å‹ç‡ã€ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³åˆ†æ
# - åŒ…æ‹¬çš„ãªã‚°ãƒ©ãƒ•ã«ã‚ˆã‚‹å¤šè§’çš„åˆ†æ
